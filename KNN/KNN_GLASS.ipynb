{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=read_csv('glass.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    76\n",
       "1    70\n",
       "7    29\n",
       "3    17\n",
       "5    13\n",
       "6     9\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   RI      214 non-null    float64\n",
      " 1   Na      214 non-null    float64\n",
      " 2   Mg      214 non-null    float64\n",
      " 3   Al      214 non-null    float64\n",
      " 4   Si      214 non-null    float64\n",
      " 5   K       214 non-null    float64\n",
      " 6   Ca      214 non-null    float64\n",
      " 7   Ba      214 non-null    float64\n",
      " 8   Fe      214 non-null    float64\n",
      " 9   Type    214 non-null    int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 16.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   RI      214 non-null    float64\n",
      " 1   Na      214 non-null    float64\n",
      " 2   Mg      214 non-null    float64\n",
      " 3   Al      214 non-null    float64\n",
      " 4   Si      214 non-null    float64\n",
      " 5   K       214 non-null    float64\n",
      " 6   Ca      214 non-null    float64\n",
      " 7   Ba      214 non-null    float64\n",
      " 8   Fe      214 non-null    float64\n",
      " 9   Type    214 non-null    int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 16.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df.values\n",
    "\n",
    "\n",
    "X = array[:, 0:-1]\n",
    "Y = array[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.52101, 13.64   ,  4.49   , ...,  8.75   ,  0.     ,  0.     ],\n",
       "       [ 1.51761, 13.89   ,  3.6    , ...,  7.83   ,  0.     ,  0.     ],\n",
       "       [ 1.51618, 13.53   ,  3.55   , ...,  7.78   ,  0.     ,  0.     ],\n",
       "       ...,\n",
       "       [ 1.52065, 14.36   ,  0.     , ...,  8.44   ,  1.64   ,  0.     ],\n",
       "       [ 1.51651, 14.38   ,  0.     , ...,  8.48   ,  1.57   ,  0.     ],\n",
       "       [ 1.51711, 14.23   ,  0.     , ...,  8.62   ,  1.67   ,  0.     ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6., 7., 7.,\n",
       "       7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n",
       "       7., 7., 7., 7., 7., 7., 7., 7., 7., 7.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalizing the data(scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=(X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43283582, 0.43759398, 1.        , ..., 0.30855019, 0.        ,\n",
       "        0.        ],\n",
       "       [0.28358209, 0.47518797, 0.80178174, ..., 0.22304833, 0.        ,\n",
       "        0.        ],\n",
       "       [0.22080773, 0.42105263, 0.79064588, ..., 0.21840149, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.41703248, 0.54586466, 0.        , ..., 0.27973978, 0.52063492,\n",
       "        0.        ],\n",
       "       [0.23529412, 0.54887218, 0.        , ..., 0.28345725, 0.4984127 ,\n",
       "        0.        ],\n",
       "       [0.26163301, 0.52631579, 0.        , ..., 0.2964684 , 0.53015873,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dividing the data in two parts\n",
    "# Train Data\n",
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.78      0.78      0.78        23\n",
      "         2.0       0.64      0.67      0.65        21\n",
      "         3.0       0.33      0.50      0.40         2\n",
      "         5.0       0.40      1.00      0.57         2\n",
      "         6.0       1.00      0.40      0.57         5\n",
      "         7.0       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.69      0.70      0.65        65\n",
      "weighted avg       0.77      0.72      0.73        65\n",
      " 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.72      0.78      0.75        23\n",
      "         2.0       0.67      0.67      0.67        21\n",
      "         3.0       1.00      0.50      0.67         2\n",
      "         5.0       0.20      0.50      0.29         2\n",
      "         6.0       1.00      0.40      0.57         5\n",
      "         7.0       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.75      0.61      0.64        65\n",
      "weighted avg       0.75      0.71      0.71        65\n",
      " 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.72      0.78      0.75        23\n",
      "         2.0       0.67      0.67      0.67        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.25      0.50      0.33         2\n",
      "         6.0       1.00      0.40      0.57         5\n",
      "         7.0       0.77      0.83      0.80        12\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.57      0.53      0.52        65\n",
      "weighted avg       0.70      0.69      0.68        65\n",
      " 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.67      0.78      0.72        23\n",
      "         2.0       0.67      0.67      0.67        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       1.00      0.20      0.33         5\n",
      "         7.0       0.77      0.83      0.80        12\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.52      0.41      0.42        65\n",
      "weighted avg       0.67      0.66      0.64        65\n",
      " 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.68      0.83      0.75        23\n",
      "         2.0       0.70      0.67      0.68        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.77      0.83      0.80        12\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.36      0.39      0.37        65\n",
      "weighted avg       0.61      0.66      0.63        65\n",
      " 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.66      0.83      0.73        23\n",
      "         2.0       0.67      0.67      0.67        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.71      0.83      0.77        12\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.34      0.39      0.36        65\n",
      "weighted avg       0.58      0.66      0.62        65\n",
      " 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.67      0.78      0.72        23\n",
      "         2.0       0.68      0.71      0.70        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.71      0.83      0.77        12\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.34      0.39      0.36        65\n",
      "weighted avg       0.59      0.66      0.62        65\n",
      " 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.71      0.87      0.78        23\n",
      "         2.0       0.76      0.76      0.76        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.67      0.83      0.74        12\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.36      0.41      0.38        65\n",
      "weighted avg       0.62      0.71      0.66        65\n",
      " 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.72      0.91      0.81        23\n",
      "         2.0       0.80      0.76      0.78        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.67      0.83      0.74        12\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.37      0.42      0.39        65\n",
      "weighted avg       0.64      0.72      0.67        65\n",
      " 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.70      0.83      0.76        23\n",
      "         2.0       0.73      0.76      0.74        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.67      0.83      0.74        12\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.35      0.40      0.37        65\n",
      "weighted avg       0.61      0.69      0.65        65\n",
      " 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.61      0.74      0.67        23\n",
      "         2.0       0.67      0.67      0.67        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.67      0.83      0.74        12\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.32      0.37      0.35        65\n",
      "weighted avg       0.55      0.63      0.59        65\n",
      " 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.62      0.78      0.69        23\n",
      "         2.0       0.65      0.62      0.63        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.67      0.83      0.74        12\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.32      0.37      0.34        65\n",
      "weighted avg       0.55      0.63      0.59        65\n",
      " 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.56      0.78      0.65        23\n",
      "         2.0       0.59      0.48      0.53        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.67      0.83      0.74        12\n",
      "\n",
      "    accuracy                           0.58        65\n",
      "   macro avg       0.30      0.35      0.32        65\n",
      "weighted avg       0.51      0.58      0.54        65\n",
      " 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.78      0.67        23\n",
      "         2.0       0.59      0.48      0.53        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.62      0.83      0.71        12\n",
      "\n",
      "    accuracy                           0.58        65\n",
      "   macro avg       0.30      0.35      0.32        65\n",
      "weighted avg       0.51      0.58      0.54        65\n",
      " 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.78      0.71        23\n",
      "         2.0       0.63      0.57      0.60        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.59      0.83      0.69        12\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.31      0.36      0.33        65\n",
      "weighted avg       0.54      0.62      0.57        65\n",
      " 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.61      0.83      0.70        23\n",
      "         2.0       0.56      0.43      0.49        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.56      0.83      0.67        12\n",
      "\n",
      "    accuracy                           0.58        65\n",
      "   macro avg       0.29      0.35      0.31        65\n",
      "weighted avg       0.50      0.58      0.53        65\n",
      " 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.67      0.78      0.72        23\n",
      "         2.0       0.60      0.57      0.59        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.56      0.83      0.67        12\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.30      0.36      0.33        65\n",
      "weighted avg       0.53      0.62      0.57        65\n",
      " 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.61      0.60        23\n",
      "         2.0       0.48      0.52      0.50        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.56      0.83      0.67        12\n",
      "\n",
      "    accuracy                           0.54        65\n",
      "   macro avg       0.27      0.33      0.29        65\n",
      "weighted avg       0.46      0.54      0.50        65\n",
      " 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.62      0.57      0.59        23\n",
      "         2.0       0.50      0.62      0.55        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.56      0.83      0.67        12\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.28      0.34      0.30        65\n",
      "weighted avg       0.48      0.55      0.51        65\n",
      " 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.61      0.60        23\n",
      "         2.0       0.48      0.52      0.50        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.56      0.83      0.67        12\n",
      "\n",
      "    accuracy                           0.54        65\n",
      "   macro avg       0.27      0.33      0.29        65\n",
      "weighted avg       0.46      0.54      0.50        65\n",
      " 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.61      0.62        23\n",
      "         2.0       0.54      0.67      0.60        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.59      0.83      0.69        12\n",
      "\n",
      "    accuracy                           0.58        65\n",
      "   macro avg       0.29      0.35      0.32        65\n",
      "weighted avg       0.51      0.58      0.54        65\n",
      " 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.61      0.62        23\n",
      "         2.0       0.48      0.57      0.52        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.56      0.83      0.67        12\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.28      0.34      0.30        65\n",
      "weighted avg       0.48      0.55      0.51        65\n",
      " 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.67      0.43      0.53        23\n",
      "         2.0       0.50      0.81      0.62        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.62      0.83      0.71        12\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.30      0.35      0.31        65\n",
      "weighted avg       0.51      0.57      0.52        65\n",
      " 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.60      0.39      0.47        23\n",
      "         2.0       0.47      0.76      0.58        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.62      0.83      0.71        12\n",
      "\n",
      "    accuracy                           0.54        65\n",
      "   macro avg       0.28      0.33      0.29        65\n",
      "weighted avg       0.48      0.54      0.49        65\n",
      " 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.67      0.61      0.64        23\n",
      "         2.0       0.53      0.76      0.63        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.71      0.83      0.77        12\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.32      0.37      0.34        65\n",
      "weighted avg       0.54      0.62      0.57        65\n",
      " 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.61      0.62        23\n",
      "         2.0       0.50      0.71      0.59        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.77      0.83      0.80        12\n",
      "\n",
      "    accuracy                           0.60        65\n",
      "   macro avg       0.32      0.36      0.34        65\n",
      "weighted avg       0.53      0.60      0.56        65\n",
      " 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.71      0.65      0.68        23\n",
      "         2.0       0.48      0.76      0.59        21\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.82      0.75      0.78        12\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.34      0.36      0.34        65\n",
      "weighted avg       0.56      0.62      0.58        65\n",
      " 53\n"
     ]
    }
   ],
   "source": [
    "n_neighbors=[2*i+1 for i in range(0,27)]\n",
    "for n in n_neighbors:\n",
    "    model = KNeighborsClassifier(n_neighbors=n)\n",
    "    model.fit(x_train,y_train)\n",
    "    pred=model.predict(x_test)\n",
    "    accuracy_score(y_test,pred)\n",
    "    \n",
    "    print(classification_report(y_test,pred),n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing CV result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "# choose k between 1 to 39\n",
    "k_range = [2*i+1 for i in range(0,20)]\n",
    "k_scores = []\n",
    "# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn,x_train , y_train,cv=10)\n",
    "    k_scores.append(scores.mean())\n",
    "# plot to see clearly\n",
    "plt.bar(k_range, k_scores)\n",
    "plt.plot(k_range, k_scores,color=\"red\")\n",
    "\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.xticks(k_range)\n",
    "plt.ylim(0.5,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_range[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6180952380952381"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_scores[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(x_train,y_train)\n",
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.676923076923077"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.60      0.90      0.72        20\n",
      "         2.0       0.72      0.59      0.65        22\n",
      "         3.0       0.00      0.00      0.00         4\n",
      "         5.0       0.60      0.43      0.50         7\n",
      "         6.0       1.00      0.50      0.67         4\n",
      "         7.0       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.64      0.57      0.58        65\n",
      "weighted avg       0.66      0.68      0.65        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
